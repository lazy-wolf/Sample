{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lazy-wolf/Sample/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment 4**\n",
        "\n",
        "```\n",
        "# Authoured by: Wasim Dawood Shaik\n",
        "# UNB ID: 3744476\n",
        "# Date: 4-12-2023\n",
        "```"
      ],
      "metadata": {
        "id": "d83_SVyO7EGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "BFP82Fsf1w_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KIuenMnDWReV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, Reshape, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Dataset**"
      ],
      "metadata": {
        "id": "jxbQb_4417LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "weFZW2k4WXIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebc72aa-1b5a-4403-fcaf-09dd6a0ec1f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = x_train[:10000], y_train[:10000]"
      ],
      "metadata": {
        "id": "IpGYRQg0m5qv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = x_train[:2000], y_train[:2000]"
      ],
      "metadata": {
        "id": "upBjBbg1nMJa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Info**"
      ],
      "metadata": {
        "id": "g15XjX5b19Np"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[cifar10 datset link](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data)\n",
        "\n",
        "*https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data*"
      ],
      "metadata": {
        "id": "2Mr6P0MZ2Pmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvK5qGKhWe8G",
        "outputId": "506ad0a9-91e6-4286-ba01-e1b1733c9534"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QylLXzeHWgnt",
        "outputId": "eeea414c-0631-4a8f-f025-5471c5b06d58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "wE0nQ_Q92pbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "7BRDGvI4WY_G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auto-Encoder (AE) Implementation**"
      ],
      "metadata": {
        "id": "fWHju_ED2-j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auto-Encoder Model Architecture**"
      ],
      "metadata": {
        "id": "uDcc5GQC3DcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Input Layer\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "#Encoding Layer\n",
        "x = Reshape((32*32*3,))(input_img)\n",
        "x = Dense(3000, activation='relu')(x)\n",
        "x = Dense(1500, activation='relu')(x)\n",
        "x = Dense(750, activation='relu')(x)\n",
        "encoded = Dense(350, activation='relu')(x)\n",
        "#Decoding Layer\n",
        "x = Dense(750, activation='relu')(encoded)\n",
        "x = Dense(1500, activation='relu')(x)\n",
        "x = Dense(3000, activation='relu')(x)\n",
        "x = Dense(32*32*3, activation='sigmoid')(x)\n",
        "decoded = Reshape((32, 32, 3))(x)\n",
        "#AutoEncoder Model\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "metadata": {
        "id": "Zsv1tO2PWiEt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiling the Auto-Encoder**"
      ],
      "metadata": {
        "id": "j3btgRAY3IxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.002), loss='mse')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsPSMRnKXlXA",
        "outputId": "6225b887-871c-47bb-e655-0a61092f3ea2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3000)              9219000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1500)              4501500   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 750)               1125750   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 350)               262850    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 750)               263250    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1500)              1126500   \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3000)              4503000   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3072)              9219072   \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30220922 (115.28 MB)\n",
            "Trainable params: 30220922 (115.28 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auto-Encoder Training**"
      ],
      "metadata": {
        "id": "BuX5siZS3W_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the AutoEncoder Model\n",
        "history = autoencoder.fit(x_train, x_train, validation_data=(x_test, x_test), epochs=50, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obDY9fvYYCtz",
        "outputId": "abc6bf45-8b12-47b2-f92f-117e3439c923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            " 51/313 [===>..........................] - ETA: 2:42 - loss: 0.0633"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "_Ql2TFVAXlaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Training History**\n"
      ],
      "metadata": {
        "id": "9TUQfwoA3oWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "plt.plot(history.epoch, history.history['loss'], label=\"loss\")\n",
        "plt.plot(history.epoch, history.history['val_loss'], label=\"val_loss\")\n",
        "\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AVxlEQQuXldK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auto-Encoder Evaluation**"
      ],
      "metadata": {
        "id": "RCGszQg-34YY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results=autoencoder.evaluate(x_test, x_test)\n",
        "print(\"Test Loss MSE : \", results)"
      ],
      "metadata": {
        "id": "-H1DZV5PbJfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auto Encoder Test Dataset Reconstruction**"
      ],
      "metadata": {
        "id": "Fq9p35IF4HmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_pred = autoencoder.predict(x_test)"
      ],
      "metadata": {
        "id": "_t0hqFcKXlf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_reconstruction_losses(original, reconstructed):\n",
        "    mse_loss = tf.keras.losses.mean_squared_error(original.flatten(), reconstructed.flatten()).numpy()\n",
        "    bce_loss = tf.keras.losses.binary_crossentropy(original.flatten(), reconstructed.flatten()).numpy()\n",
        "    return mse_loss, bce_loss"
      ],
      "metadata": {
        "id": "YcQOUa3ZXlij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_reconstruction_losses(x_test, x_test_pred)"
      ],
      "metadata": {
        "id": "1yONUG4WXlle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reconstruction Quality : Auto-Encoder**"
      ],
      "metadata": {
        "id": "dE6rSJZM4Xrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10  # How many image rows, we will display\n",
        "plt.figure(figsize=(20, 6 + 0.5))  # Adjust the figure size to accommodate three rows\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(4, n, i + 1)\n",
        "    original_img = x_test[i]\n",
        "    plt.imshow(original_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(4, n, i + 1 + n)\n",
        "    reconstructed_img = x_test_pred[i]\n",
        "    plt.imshow(reconstructed_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display difference\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 2)\n",
        "    difference = np.abs(original_img - reconstructed_img)\n",
        "    plt.imshow(difference)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Calculate losses\n",
        "    mse_loss, bce_loss = calculate_reconstruction_losses(original_img, reconstructed_img)\n",
        "\n",
        "    # Add captions with losses\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 3)\n",
        "    plt.axis('off')\n",
        "    loss_caption = f\"MSE: {mse_loss:.4f}\\nBCE: {bce_loss:.4f}\"\n",
        "    plt.text(0.5, 0.5, loss_caption, ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_moadRybXlpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Hyperparameters Choosed : Additional Layer, Learning Rate, Encoding Dimension/ Latent Space Dimension\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "CfpGXqDX4ixY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameter_tuning_strategy(cofig, x_train, x_test):\n",
        "  additional_layer, learning_rate, encoding_dim = config\n",
        "  possible_combinations = list(itertools.product(additional_layer, learning_rate, encoding_dim))\n",
        "  print(\"*\"*25)\n",
        "  print(f\"Possible No.of Combinations : {possible_combinations}\")\n",
        "  print(\"*\"*25)\n",
        "  hist = []\n",
        "  for i in range(len(possible_combinations)):\n",
        "    print(\"*\"*25)\n",
        "    print(f\"Combination : {i+1}\")\n",
        "    print(\"*\"*25)\n",
        "    additional_layer, learning_rate, encoding_dim = possible_combinations[i]\n",
        "    #Input Layer\n",
        "    input_img = Input(shape=(32, 32, 3))\n",
        "    #Encoding Layer\n",
        "    x = Reshape((32*32*3,))(input_img)\n",
        "    x = Dense(3000, activation='relu')(x)\n",
        "    if additional_layer:\n",
        "      x = Dense(1500, activation='relu')(x)\n",
        "    x = Dense(750, activation='relu')(x)\n",
        "    encoded = Dense(encoding_dim, activation='relu')(x)\n",
        "    #Decoding Layer\n",
        "    x = Dense(750, activation='relu')(encoded)\n",
        "    if additional_layer:\n",
        "      x = Dense(1500, activation='relu')(x)\n",
        "    x = Dense(3000, activation='relu')(x)\n",
        "    x = Dense(32*32*3, activation='sigmoid')(x)\n",
        "    decoded = Reshape((32, 32, 3))(x)\n",
        "    #AutoEncoder Model\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "    #Training the AutoEncoder Model\n",
        "    autoencoder.fit(x_train, x_train, validation_data=(x_test, x_test), epochs=50, batch_size=32)\n",
        "    test_loss = autoencoder.evaluate(x_test, x_test)\n",
        "    hist.append(list((additional_layer, learning_rate, encoding_dim, test_loss)))\n",
        "    print(f\"Combination : {i+1} -> {possible_combinations[i]} test_mse : {test_loss}\")\n",
        "    print(\"*\"*25)\n",
        "    print(\"*\"*25)\n",
        "  return hist\n"
      ],
      "metadata": {
        "id": "8JG30Ui4Xlr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different HyperParameter Cofigurations for Tuning**"
      ],
      "metadata": {
        "id": "DlsZwfsE4sJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = [[True, False], [0.001, 0.002], [175, 350]]\n",
        "\n",
        "hist = hyperparameter_tuning_strategy(config, x_train, x_test)"
      ],
      "metadata": {
        "id": "57To2DIVXlu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different HyperParameter Value's Test Losses Comparison**"
      ],
      "metadata": {
        "id": "4_kwzV2O40Z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist_hp_comb = pd.DataFrame(hist, columns=[\"Additional Layer\", \"Learning Rate\", \"Encoding Dimesnionality/Latent Sapce Dimensionality\",\"Test Loss\"])\n",
        "hist_hp_comb = hist_hp_comb.sort_values(by=[\"Test Loss\"], ascending=True)\n",
        "hist_hp_comb"
      ],
      "metadata": {
        "id": "bNuGUpz_Xlx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reconstruction Quality Changes After HyperParameter Tuning**"
      ],
      "metadata": {
        "id": "XdwudP1w456_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"*\"*25)\n",
        "print(f\"----Best Combination---- \\n Additional Layer = {hist_hp_comb.iloc[0,0]}\\n Learning Rate = {hist_hp_comb.iloc[0,1]}\\n Encoding Dimesnionality/Latent Sapce Dimensionality = {hist_hp_comb.iloc[0,2]}\\n\")\n",
        "print(\"*\"*25)\n",
        "print(\"*\"*25)\n",
        "before_mse = np.round(results, 4)\n",
        "after_mse = np.round(hist_hp_comb.iloc[0, 3], 4)\n",
        "print(f'Results Before Tunning:\\n Test Loss MSE: {before_mse}\\n')\n",
        "print(f'Results After Tunning:\\n Test Loss MSE: {after_mse}\\n')\n",
        "print(f'{np.round((before_mse-after_mse)*100/before_mse)}% Reconstruction Quality Improvement')"
      ],
      "metadata": {
        "id": "ghDXYGWZXl07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best AutoEncoder Model after Tuning**"
      ],
      "metadata": {
        "id": "QSIxVvTE5EGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "additional_layer, learning_rate, encoding_dim = list(hist_hp_comb.iloc[0, :3])"
      ],
      "metadata": {
        "id": "qDXdbDb7Xl3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Auto-Encoder Architecture**"
      ],
      "metadata": {
        "id": "Wvk_yp9WA77A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Input Layer\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "#Encoding Layer\n",
        "x = Reshape((32*32*3,))(input_img)\n",
        "x = Dense(3000, activation='relu')(x)\n",
        "if additional_layer:\n",
        "  x = Dense(1500, activation='relu')(x)\n",
        "x = Dense(750, activation='relu')(x)\n",
        "encoded = Dense(encoding_dim, activation='relu')(x)\n",
        "#Decoding Layer\n",
        "x = Dense(750, activation='relu')(encoded)\n",
        "if additional_layer:\n",
        "  x = Dense(1500, activation='relu')(x)\n",
        "x = Dense(3000, activation='relu')(x)\n",
        "x = Dense(32*32*3, activation='sigmoid')(x)\n",
        "decoded = Reshape((32, 32, 3))(x)"
      ],
      "metadata": {
        "id": "RYagB0TUXl6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compiling the Best Auto-Encoder**"
      ],
      "metadata": {
        "id": "sgCxwuaBBFL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#AutoEncoder Model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "esksORiQ22hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Autoencoder - Encoder Model**"
      ],
      "metadata": {
        "id": "OCSgmm_RBHwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the encoder model\n",
        "encoder_best = Model(input_img, encoded)"
      ],
      "metadata": {
        "id": "Kk_Aabrn5mOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Auto-Encoder Training**"
      ],
      "metadata": {
        "id": "johEbdhQBSe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the AutoEncoder Model\n",
        "history = autoencoder.fit(x_train, x_train, validation_data=(x_test, x_test), epochs=50, batch_size=32)\n"
      ],
      "metadata": {
        "id": "nIpwc-py3BUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Training History**"
      ],
      "metadata": {
        "id": "KnafDoHrBcpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "plt.plot(history.epoch, history.history['loss'], label=\"loss\")\n",
        "plt.plot(history.epoch, history.history['val_loss'], label=\"val_loss\")\n",
        "\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L_9_Govwol36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Auto-Encoder Evaluation**"
      ],
      "metadata": {
        "id": "YD0waGLfBkqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = autoencoder.evaluate(x_test, x_test)\n",
        "print(\"Test Loss MSE : \", test_loss)"
      ],
      "metadata": {
        "id": "a--RS_sG3BXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Auto Encoder Test Dataset Reconstruction**"
      ],
      "metadata": {
        "id": "MbU_M_jJB5jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_pred = autoencoder.predict(x_test)\n",
        "mse_loss, bce_loss = calculate_reconstruction_losses(x_test, x_test_pred)\n",
        "(mse_loss, bce_loss)"
      ],
      "metadata": {
        "id": "kg84fjHU3BaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reconstruction Quality : Best Auto-Encoder**"
      ],
      "metadata": {
        "id": "KbwkI_nFChkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10  # # How many image rows, we will display\n",
        "plt.figure(figsize=(20, 6 + 0.5))  # Adjust the figure size to accommodate three rows\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(4, n, i + 1)\n",
        "    original_img = x_test[i]\n",
        "    plt.imshow(original_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(4, n, i + 1 + n)\n",
        "    reconstructed_img = x_test_pred[i]\n",
        "    plt.imshow(reconstructed_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display difference\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 2)\n",
        "    difference = np.abs(original_img - reconstructed_img)\n",
        "    plt.imshow(difference)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Calculate losses\n",
        "    mse_loss, bce_loss = calculate_reconstruction_losses(original_img, reconstructed_img)\n",
        "\n",
        "    # Add captions with losses\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 3)\n",
        "    plt.axis('off')\n",
        "    loss_caption = f\"MSE: {mse_loss:.4f}\\nBCE: {bce_loss:.4f}\"\n",
        "    plt.text(0.5, 0.5, loss_caption, ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5lvH-vdu3BdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Auto-Encoder (VAE) Implementation**"
      ],
      "metadata": {
        "id": "nxUlUYR0CqwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Auto-Encoder Model Architecture**"
      ],
      "metadata": {
        "id": "sK31zbZjC3zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "original_dim = 3072  # 32*32*3\n",
        "latent_dim = 2\n",
        "intermediate_dim = 128\n",
        "epochs = 50\n",
        "epsilon_std = 1.0\n",
        "\n",
        "# Encoder network\n",
        "x = Input(shape=(original_dim,), name='input')\n",
        "h = Dense(intermediate_dim, activation='relu', name='encoding')(x)\n",
        "z_mean = Dense(latent_dim, name='mean')(h)\n",
        "z_log_var = Dense(latent_dim, name='log-variance')(h)\n",
        "\n",
        "# Sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# Sample from the latent distribution\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# Decoder network\n",
        "decoder_h = Dense(intermediate_dim, activation='relu', name='decoder_h')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid', name='decoder_mean')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "# VAE model\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "# Loss function: reconstruction loss + KL divergence\n",
        "reconstruction_loss = binary_crossentropy(x, x_decoded_mean) * original_dim\n",
        "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer=Adam(learning_rate=0.002))"
      ],
      "metadata": {
        "id": "QWnswCzMKybo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "cZHNVyty5d8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_vae = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test_vae = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "metadata": {
        "id": "AhZTksK9JBqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Auto-Encoder Model Training**"
      ],
      "metadata": {
        "id": "82xLwLpYDPfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the AutoEncoder Model\n",
        "history = vae.fit(x_train_vae, x_train_vae, epochs=epochs, batch_size=batch_size, validation_data=(x_test_vae, x_test_vae))"
      ],
      "metadata": {
        "id": "XJ_HgLpz5EIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "plt.plot(history.epoch, history.history['loss'], label=\"loss\")\n",
        "plt.plot(history.epoch, history.history['val_loss'], label=\"val_loss\")\n",
        "\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8ZIzcDnMaaKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = vae.evaluate(x_test_vae, x_test_vae)\n",
        "print(\"Test Loss VAE : \", results)"
      ],
      "metadata": {
        "id": "705iZSJBJS0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_pred = vae.predict(x_test_vae)"
      ],
      "metadata": {
        "id": "-y9lX_UR69iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_loss, bce_loss = calculate_reconstruction_losses(x_test_vae, x_test_pred)\n",
        "(mse_loss, bce_loss)"
      ],
      "metadata": {
        "id": "do3WFfxlKVQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10  # # How many image rows, we will display\n",
        "plt.figure(figsize=(20, 6 + 0.5))  # Adjust the figure size to accommodate three rows\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(4, n, i + 1)\n",
        "    original_img = x_test_vae[i].reshape(32,32,3)\n",
        "    plt.imshow(original_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(4, n, i + 1 + n)\n",
        "    reconstructed_img = x_test_pred[i].reshape(32,32,3)\n",
        "    plt.imshow(reconstructed_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display difference\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 2)\n",
        "    difference = np.abs(original_img - reconstructed_img)\n",
        "    plt.imshow(difference)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Calculate losses\n",
        "    mse_loss, bce_loss = calculate_reconstruction_losses(original_img, reconstructed_img)\n",
        "\n",
        "    # Add captions with losses\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 3)\n",
        "    plt.axis('off')\n",
        "    loss_caption = f\"MSE: {mse_loss:.4f}\\nBCE: {bce_loss:.4f}\"\n",
        "    plt.text(0.5, 0.5, loss_caption, ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X87E5jck4tDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-N_dlKZtJyzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcC26tbbOQJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcuN143KJy2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameter_tuning_strategy(cofig, x_train, x_test):\n",
        "  intermediate_dim, latent_dim, learning_rate = config\n",
        "  possible_combinations = list(itertools.product(intermediate_dim, latent_dim, learning_rate))\n",
        "  print(\"*\"*25)\n",
        "  print(f\"Possible No.of Combinations : {possible_combinations}\")\n",
        "  print(\"*\"*25)\n",
        "  hist = []\n",
        "  for i in range(len(possible_combinations)):\n",
        "    print(\"*\"*25)\n",
        "    print(f\"Combination : {i+1}\")\n",
        "    print(\"*\"*25)\n",
        "    intermediate_dim, latent_dim, learning_rate = possible_combinations[i]\n",
        "    # Hyperparameters\n",
        "    batch_size = 32\n",
        "    original_dim = 3072  # 32*32*3\n",
        "    epochs = 50\n",
        "    epsilon_std = 1.0\n",
        "\n",
        "    # Encoder network\n",
        "    x = Input(shape=(original_dim,), name='input')\n",
        "    h = Dense(intermediate_dim, activation='relu', name='encoding')(x)\n",
        "    z_mean = Dense(latent_dim, name='mean')(h)\n",
        "    z_log_var = Dense(latent_dim, name='log-variance')(h)\n",
        "\n",
        "    # Sampling function\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n",
        "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "    # Sample from the latent distribution\n",
        "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "    # Decoder network\n",
        "    decoder_h = Dense(intermediate_dim, activation='relu', name='decoder_h')\n",
        "    decoder_mean = Dense(original_dim, activation='sigmoid', name='decoder_mean')\n",
        "    h_decoded = decoder_h(z)\n",
        "    x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "    # VAE model\n",
        "    vae = Model(x, x_decoded_mean)\n",
        "\n",
        "    # Loss function: reconstruction loss + KL divergence\n",
        "    reconstruction_loss = binary_crossentropy(x, x_decoded_mean) * original_dim\n",
        "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "    vae.add_loss(vae_loss)\n",
        "    vae.compile(optimizer=Adam(learning_rate=learning_rate))\n",
        "    #Training the AutoEncoder Model\n",
        "    x_train_vae = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "    x_test_vae = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "    history = vae.fit(x_train_vae, x_train_vae, shuffle=True, epochs=epochs, batch_size=batch_size, validation_data=(x_test_vae, x_test_vae))\n",
        "    test_loss = vae.evaluate(x_test_vae, x_test_vae)\n",
        "    hist.append(list((intermediate_dim, latent_dim, learning_rate, test_loss)))\n",
        "    print(f\"Combination : {i+1} -> {possible_combinations[i]}  test_mse : {test_loss}\")\n",
        "    print(\"*\"*25)\n",
        "    print(\"*\"*25)\n",
        "  return hist"
      ],
      "metadata": {
        "id": "ECJrGmNr4tw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = [[256, 512], [4, 8], [0.001, 0.0015]]\n",
        "\n",
        "hist = hyperparameter_tuning_strategy(config, x_train, x_test)"
      ],
      "metadata": {
        "id": "U3B8Dxi84t0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_hp_comb = pd.DataFrame(hist, columns=[\"Intermediate Dimensionilty\", \"Latent Dimensionility Space\", \"Learning Rate\", \"Test Loss VAE\"])\n",
        "hist_hp_comb = hist_hp_comb.sort_values(by=[\"Test Loss VAE\"], ascending=True)\n",
        "hist_hp_comb"
      ],
      "metadata": {
        "id": "Vt2nO8GW4t3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"*\"*25)\n",
        "print(f\"----Best Combination---- \\n Intermediate Dimensionilty = {hist.iloc[0,0]}\\n Latent Dimensionility Space = {hist.iloc[0,1]}\\n Learning Rate = {hist.iloc[0,2]}\\n\")\n",
        "print(\"*\"*25)\n",
        "print(\"*\"*25)\n",
        "before_mse = np.round(results, 4)\n",
        "after_mse = np.round(hist.iloc[0, 3], 4)\n",
        "print(f'Results Before Tunning:\\n Test Loss MSE: {before_mse}\\n')\n",
        "print(f'Results After Tunning:\\n Test Loss MSE: {after_mse}\\n')\n",
        "print(f'{np.round((before_mse-after_mse)*100/before_mse)}% Reconstruction Quality Improvement')"
      ],
      "metadata": {
        "id": "cotDgSLN9piP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(hist.iloc[0, :2])"
      ],
      "metadata": {
        "id": "-D0wgvfjy5Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intermediate_dim, latent_dim, learning_rate = list(hist.iloc[0, :3])"
      ],
      "metadata": {
        "id": "clD4R2kR9plY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "original_dim = 3072  # 32*32*3\n",
        "latent_dim = int(latent_dim)\n",
        "intermediate_dim = int(intermediate_dim)\n",
        "epochs = 25\n",
        "epsilon_std = 1.0\n",
        "\n",
        "# Encoder network\n",
        "x = Input(shape=(original_dim,), name='input')\n",
        "h = Dense(intermediate_dim, activation='relu', name='encoding')(x)\n",
        "z_mean = Dense(latent_dim, name='mean')(h)\n",
        "z_log_var = Dense(latent_dim, name='log-variance')(h)\n",
        "\n",
        "# Sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "\n",
        "# Sample from the latent distribution\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "\n",
        "# Decoder network\n",
        "decoder_h = Dense(intermediate_dim, activation='relu', name='decoder_h')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid', name='decoder_mean')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "# VAE model\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "# Loss function: reconstruction loss + KL divergence\n",
        "reconstruction_loss = binary_crossentropy(x, x_decoded_mean) * original_dim\n",
        "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer=Adam(learning_rate=learning_rate))\n",
        "# vae.summary()"
      ],
      "metadata": {
        "id": "biGHXB85sSEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_vae = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test_vae = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ],
      "metadata": {
        "id": "r2KQ755T0O3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the AutoEncoder Model\n",
        "history = vae.fit(x_train_vae, x_train_vae, shuffle=True, epochs=epochs, batch_size=batch_size, validation_data=(x_test_vae, x_test_vae))"
      ],
      "metadata": {
        "id": "vGXurfCSsSHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "plt.plot(history.epoch, history.history['loss'], label=\"loss\")\n",
        "plt.plot(history.epoch, history.history['val_loss'], label=\"val_loss\")\n",
        "\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iTuf2hSJrSlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = vae.evaluate(x_test_vae, x_test_vae)"
      ],
      "metadata": {
        "id": "CqsHZZ4wrSoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_pred = vae.predict(x_test_vae)"
      ],
      "metadata": {
        "id": "QAyGP2lgrSrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_loss, bce_loss = calculate_reconstruction_losses(x_test_vae, x_test_pred)"
      ],
      "metadata": {
        "id": "5mvo6qCdrSuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10  # How many image rows, we will display\n",
        "plt.figure(figsize=(20, 6 + 0.5))  # Adjust the figure size to accommodate three rows\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(4, n, i + 1)\n",
        "    original_img = x_test_vae[i].reshape(32,32,3)\n",
        "    plt.imshow(original_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(4, n, i + 1 + n)\n",
        "    reconstructed_img = x_test_pred[i].reshape(32,32,3)\n",
        "    plt.imshow(reconstructed_img)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display difference\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 2)\n",
        "    difference = np.abs(original_img - reconstructed_img)\n",
        "    plt.imshow(difference)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Calculate losses\n",
        "    mse_loss, bce_loss = calculate_reconstruction_losses(original_img, reconstructed_img)\n",
        "\n",
        "    # Add captions with losses\n",
        "    ax = plt.subplot(4, n, i + 1 + n * 3)\n",
        "    plt.axis('off')\n",
        "    loss_caption = f\"MSE: {mse_loss:.4f}\\nBCE: {bce_loss:.4f}\"\n",
        "    plt.text(0.5, 0.5, loss_caption, ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ChURrjWprSw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a model to project inputs on the latent space\n",
        "encoder = Model(x, z_mean)"
      ],
      "metadata": {
        "id": "ANFCPQWWrSza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a 2D plot of the digit classes in the latent space\n",
        "x_test_encoded = encoder.predict(x_test_vae, batch_size=batch_size)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cExAu398rNGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8eFfm1z_rNJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HPqPlZ9rNML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ot8rI9bSrNO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GoRaMJk4rNSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nBBaVeDrrNVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8th2nFrrNXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qzTMRQHXrNdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fcWeexyArNgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sa8Y7uQDrNj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4B0X6HArNm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_jdjxCGorNqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9rlO-YG9prr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V5KHqu4j9pur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GiUNAkZh9pyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuGkqe5_4t5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNEheH9m4t9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85wxFZRT4t_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}